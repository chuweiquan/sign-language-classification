{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (27455, 785)\n",
      "Shape of Test: (7172, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train: \" + str(train.shape))\n",
    "print(\"Shape of Test: \" + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the dataframe for both train and test have ground truth labels inside, so lets separate the X and y\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"label\").to_numpy()\n",
    "y_train = train['label'].to_numpy()\n",
    "X_test = test.drop(columns=\"label\").to_numpy()\n",
    "y_test = test['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save the images and labels, uncomment the codes and run everything\n",
    "# https://stackoverflow.com/questions/57103190/how-to-convert-1d-array-to-3d-array-convert-grayscale-image-so-rgb-format\n",
    "\n",
    "def resize_img(array):\n",
    "    img_2d = np.reshape(array, (28, 28))\n",
    "    width, height = img_2d.shape\n",
    "    img = np.empty((width, height, 3), dtype=np.uint8)\n",
    "    img[:, :, 0] = img_2d\n",
    "    img[:, :, 1] = img_2d\n",
    "    img[:, :, 2] = img_2d\n",
    "    \n",
    "    pil_img = tf.keras.preprocessing.image.array_to_img(img)\n",
    "    return pil_img\n",
    "\n",
    "# image_path_train = \"images/train\"\n",
    "# image_path_test = \"images/test\"\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    img = resize_img(X_train[i])\n",
    "    train_images.append(img)\n",
    "#     img.save(f\"{image_path_train}/{i}.png\")\n",
    "\n",
    "for j in range(len(X_test)):\n",
    "    img = resize_img(X_test[j])\n",
    "    test_images.append(img)\n",
    "#     img.save(f\"{image_path_test}/{j}.png\")\n",
    "\n",
    "# savetxt('labels/train_labels.csv', y_train, delimiter=',')\n",
    "# savetxt('labels/test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  2, 13, 16,  8, 22, 18, 10, 20, 17, 19, 21, 23, 24,  1, 12,\n",
       "       11, 15,  4,  0,  5,  7, 14], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that there are 24 unique labels in the dataset and each label represents a letter from A to Z (excl J and Z)\n",
    "print(train['label'].nunique())\n",
    "train[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "    9: 'K',\n",
    "    10: 'L',\n",
    "    11: 'M',\n",
    "    12: 'N',\n",
    "    13: 'O',\n",
    "    14: 'P',\n",
    "    15: 'Q',\n",
    "    16: 'R',\n",
    "    17: 'S',\n",
    "    18: 'T',\n",
    "    19: 'U',\n",
    "    20: 'V',\n",
    "    21: 'W',\n",
    "    22: 'X',\n",
    "    23: 'Y',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will define a function to resize the image to the given dimensions as different pretrained models here \n",
    "# would have different dimension requirements. We will also scale down the pixel values in this function\n",
    "\n",
    "def resize_images(minSize, train_size, test_size):\n",
    "    new_train = []\n",
    "    new_test = []\n",
    "    for i in range(train_size):\n",
    "        img = cv2.imread('images/train/' + str(i) + '.png')\n",
    "        res = cv2.resize(img, dsize=(minSize, minSize), interpolation=cv2.INTER_CUBIC)\n",
    "        new_train.append(res)\n",
    "        \n",
    "    for j in range(test_size):\n",
    "        img = cv2.imread('images/test/' + str(j) + '.png')\n",
    "        res = cv2.resize(img, dsize=(minSize, minSize), interpolation=cv2.INTER_CUBIC)\n",
    "        new_test.append(res)\n",
    "    \n",
    "    return np.array(new_train) / 255, np.array(new_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 27455\n",
    "test_len = 7172\n",
    "\n",
    "X_train_scaled, X_test_scaled = resize_images(28, train_len, test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 1.5551 - accuracy: 0.5353\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 0.0204 - accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 0.0332 - accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 2.0239e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 9.5006e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29da1dd10d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(), \n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.2533 - accuracy: 0.9527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25328513979911804, 0.9527328610420227]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.argmax(tf.nn.softmax(predictions[0])) # convert into a probability score and get the highest\n",
    "alphabets[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# loading pretrained models\n",
    "mobilenet_v2 = tf.keras.applications.MobileNetV2(input_shape=(32,32,3), include_top=False, weights='imagenet')\n",
    "vgg19 = tf.keras.applications.VGG19(input_shape=(32,32,3), include_top=False, weights='imagenet')\n",
    "inceptionv3 = tf.keras.applications.InceptionV3(input_shape=(75,75,3), include_top=False, weights='imagenet')\n",
    "resnet50 = tf.keras.applications.ResNet50(input_shape=(32,32,3), include_top=False, weights='imagenet')\n",
    "efficientnet = tf.keras.applications.EfficientNetB1(input_shape=(32,32,3), include_top=False, weights='imagenet')\n",
    "\n",
    "\n",
    "# efficientnet has B0 to B7 - need to find out the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 15s 15ms/step - loss: 2.5010 - accuracy: 0.3009\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 12s 14ms/step - loss: 1.5360 - accuracy: 0.5449\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 12s 15ms/step - loss: 1.2849 - accuracy: 0.6179\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 12s 14ms/step - loss: 1.1223 - accuracy: 0.6729\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 12s 14ms/step - loss: 0.9928 - accuracy: 0.7128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29da3f70190>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = 27455\n",
    "test_len = 7172\n",
    "X_train_scaled_mobilenet, X_test_scaled_mobilenet = resize_images(32, train_len, test_len)\n",
    "\n",
    "mobilenet_model = models.Sequential([\n",
    "  mobilenet_v2,\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "mobilenet_model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "mobilenet_model.fit(X_train_scaled_mobilenet, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 4s 17ms/step - loss: 1.9218 - accuracy: 0.4727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9217798709869385, 0.4726715087890625]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_model.evaluate(X_test_scaled_mobilenet, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 94s 93ms/step - loss: 0.6202 - accuracy: 0.8352\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 85s 99ms/step - loss: 0.0126 - accuracy: 0.9984\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 85s 99ms/step - loss: 0.0192 - accuracy: 0.9956\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 66s 77ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 63s 74ms/step - loss: 0.0037 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29dd873c7c0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = 27455\n",
    "test_len = 7172\n",
    "X_train_scaled_inception, X_test_scaled_inception = resize_images(75, train_len, test_len)\n",
    "\n",
    "mobilenet_model = models.Sequential([\n",
    "  inceptionv3,\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "mobilenet_model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "mobilenet_model.fit(X_train_scaled_inception, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 18s 72ms/step - loss: 0.7914 - accuracy: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7914420962333679, 0.8481594920158386]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_model.evaluate(X_test_scaled_inception, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
